---
title: "R Notebook"
output: html_notebook
---

This notebook will explore text reuse in Indain treaties at the paragraph level. 
```{r}
library(rvest)
library(magrittr)
library(tidyverse)
library(stringr)
library(pbapply)
library(parallel)
library(textreuse)
library(dplyr)
library(igraph)
library(ggplot2)
library(stringr)
library(data.table)
library(Matrix)

```

###Creating the Corpus without Minhashes
```{r createcorpus, cache=TRUE}
corpus <- TextReuseCorpus(list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-paragraphs", 
                   pattern = "*.txt",
                   full.names = TRUE), tokenizer = tokenize_ngrams, n = 5,
                          progress = FALSE)
saveRDS()
```

###Creating the Corpus with Minhashes

```{r createcorpus2, cache=TRUE}
minhash <- minhash_generator(n = 40, seed = 3552)

corpus2 <- TextReuseCorpus(list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-paragraphs", 
                   pattern = "*.txt",
                   full.names = TRUE), tokenizer = tokenize_ngrams, n = 5,
                          minhash_func = minhash, keep_tokens = TRUE,
                          progress = FALSE)

wc <- wordcount(corpus2)

corpus2 <- corpus2[wc >= 40]

#saveRDS(corpus2, "minhashed_corpus_par_level.rds")
#corpus2 <- readRDS("minhashed_corpus_par_level.rds")
```



```{r}

lsh_threshold(h = 40, b = 20)

buckets <- lsh(corpus2, bands = 20, progress = FALSE)
buckets
```

###Finding Candidates
```{r}
#matches <- lsh_query(buckets, "19000630400")
#matches

candidates <- lsh_candidates(buckets)

#saveRDS(candidates,"candidates_par_level.rds")
#candidates <- readRDS("candidates_par_level.rds")
 
```

### Comparing Candidates
```{r}

similarities <-lsh_compare(candidates, corpus2, jaccard_similarity)
```

Histogram of similarities
```{r} 
hist(similarities$score, breaks = 100) 
```
Filtering out the candidates that turned out not to be matches. 
```{r}
matches <- filter(similarities, score> .2)
hist(matches$score, breaks = 100)
``` 

```{r}

```


```{r}
get_treaty <- function(x) {
  str_sub(x, 1, 7)
}
similarities$a %>% sample(10) %>% get_treaty()


similarities %>% 
  mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
  count(treaty_a, treaty_b) %>% 
  arrange(desc(n)) %>% 
  filter(treaty_a != treaty_b) %>%
  View


matches %>% 
  mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
  count(treaty_a, treaty_b) %>% 
  arrange(desc(n)) %>% 
  filter(treaty_a != treaty_b) %>%
   View


fd_matches =  (matches %>% mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
  count(treaty_a, treaty_b) %>% 
  arrange(desc(n)) %>% 
  filter(treaty_a != treaty_b)) 
```

Making a Network Graph
```{r}

sample_graph <- graph.data.frame(fd_matches,directed = FALSE)

plot(sample_graph, 
     layout = layout.auto,
    vertex.label.cex = 0.7,
    margin = -0.6,
     vertex.size = 1,
    edge.width = fd_matches$n >3)
    
  

```
```{r}
document_id <- basename(parsed_treaties$file) %>% str_replace("\\.htm", "")

documents <- data_frame(document_id = fd_matches$treaty_a) %>% 
  left_join(parsed_treaties, by ="document_id")


documents <- data_frame(document_id = rownames(dtm)) %>% 
  left_join(us_subjects_moml, by = "document_id")  
  



filenames <- str_c("treaty-paragraphs/", doc_id, ".txt")

  
documents <- fd_matches(basename = fd_matches$treaty_a) %>% 
  leftjoin (parsed_treaties, by ="basename")
```

```{r}
documents <- data_frame(basename = fd_matches$treaty_a) %>% 
  left_join(parsed_treaties, by ="basename")
```
Affinity Propogation Clustering
```{r}

scores_clustering <- matches

section_names <- lsh_subset(scores_clustering)

lookup <- data_frame(section_names, index = 1:length(section_names))

lookup

scores_clustering <- scores_clustering %>% 
  left_join(lookup, by = c("a" = "section_names")) %>% 
  left_join(lookup, by = c("b" = "section_names")) 

scores_clustering

n <- length(section_names)
m <- sparseMatrix(i = scores_clustering$index.x,
                  j = scores_clustering$index.y,
                  x = scores_clustering$score,
                  dims = c(n, n), symmetric = TRUE)
colnames(m) <- section_names
rownames(m) <- section_names



cluster_cache <- "cache/clusters.rds"
if (!file.exists(cluster_cache)) {
  timing <- system.time(
    clu <- apcluster(s = m,
                     maxits = 100e3, convits = 10e3,
                     q = 0,
                     lam = 0.975,
                     seed = 42325, 
                     includeSim = TRUE,
                     )
  )
  require("RPushbullet")
  pbPost(title = "Clustering finished",
         body = paste0("Finished in ", timing[["elapsed"]], "."))
  saveRDS(clu, cluster_cache)
} else {
  clu <- readRDS(cluster_cache)
}


clu <- apcluster(negDistMat(r = 2), dtm3, details = TRUE)
ap_clusters <- clu@clusters 
names(ap_clusters) <- names(clu@exemplars)
ap_clusters <- lapply(ap_clusters, names)
ap_clusters <- map_df(names(ap_clusters), function(x) {
  tibble(exemplar = x, document_id = ap_clusters[[x]])
})
ap_clusters %>% left_join(us_items, by = "document_id") %>% View
```





