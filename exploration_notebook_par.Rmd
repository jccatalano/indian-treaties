---
title: "R Notebook"
output: html_notebook
---
#Text Reuse, Clustering

This notebook will explore text reuse in Indain treaties at the paragraph level and clustering at the paragraph and document level.First, some general information regarding Indian treaties is explored. 
```{r}
library(rvest)
library(magrittr)
library(tidyverse)
library(stringr)
library(pbapply)
library(parallel)
library(textreuse)
library(dplyr)
library(igraph)
library(ggplot2)
library(stringr)
library(data.table)
library(Matrix)
library(tokenizers)
library(text2vec)
library(broom)
library(apcluster)
library(readr)
```
###General Analysis


```{r}
#dtm2 is generated below.

parsed_treaties <- readRDS("parsed_treaties.rds")
addyear <- basename(parsed_treaties$file) %>% str_replace("\\.htm", ".txt")


parsed_treaties <- parsed_treaties %>% 
  mutate(document_id = basename(parsed_treaties$file) %>% str_replace("\\.htm", ".txt"))

#dtm2 <- dtm2 %>%
#  mutate(document_id = rownames(dtm2))
         
  
dtm_to_df <- function(x, words) {
  stopifnot(is.character(words))
  out <- as_tibble(as.data.frame(as.matrix(x[, words])))
  colnames(out) <- words
  ids <- str_replace_all(rownames(x), "\\.txt", "")
  ids <- str_split_fixed(ids, "-", n = 2)
  out %>% 
    mutate(document_id = ids[ , 1, drop = TRUE])
          }
  
words_of_interest <- c("horse", "indian", "death", "buffalo")

counts <- dtm_to_df(dtm2, words_of_interest) %>% 
  gather(word, count, -document_id) %>% 
  filter(count > 0)

item_years <- parsed_treaties %>% 
  select(document_id, year)

counts %>% 
  group_by(document_id, word) %>% 
  summarize(count = sum(count)) %>% 
  left_join(parsed_treaties, by = "document_id") %>% 
  group_by(year, word) %>% 
  summarize(count = sum(count)) %>% 
  ggplot(aes(x = year, y = count, color = word)) +
  geom_point() +
  geom_smooth(span = 0.1, se = FALSE) +
  labs(title = "A Title") + 
  xlim(1760,1890)
```


###Creating the Corpus without Minhashes
```{r createcorpus, cache=TRUE}
corpus <- TextReuseCorpus(list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-paragraphs", 
                   pattern = "*.txt",
                   full.names = TRUE), tokenizer = tokenize_ngrams, n = 5,
                          progress = FALSE)
#saveRDS()
```

###Creating the Corpus with Minhashes

```{r createcorpus2, cache=TRUE}
minhash <- minhash_generator(n = 40, seed = 3552)

corpus2 <- TextReuseCorpus(list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-paragraphs", 
                   pattern = "*.txt",
                   full.names = TRUE), tokenizer = tokenize_ngrams, n = 5,
                          minhash_func = minhash, keep_tokens = TRUE,
                          progress = FALSE)

wc <- wordcount(corpus2)

corpus2 <- corpus2[wc >= 40]

#saveRDS(corpus2, "minhashed_corpus_par_level.rds")
#corpus2 <- readRDS("minhashed_corpus_par_level.rds")
```



```{r}

lsh_threshold(h = 40, b = 20)

buckets <- lsh(corpus2, bands = 20, progress = FALSE)
buckets
```

###Finding Candidates
```{r}
#matches <- lsh_query(buckets, "19000630400")
#matches

candidates <- lsh_candidates(buckets)

#saveRDS(candidates,"candidates_par_level.rds")
#candidates <- readRDS("candidates_par_level.rds")
 
```

### Comparing Candidates
```{r}

similarities <-lsh_compare(candidates, corpus2, jaccard_similarity)
```

Histogram of similarities
```{r} 
hist(similarities$score, breaks = 100) 
```
Filtering out the candidates that turned out not to be matches. 
```{r}

similarities <- filter(similarities, score> .2)
hist(matches$score, breaks = 100)
``` 


```{r}
get_treaty <- function(x) {
  str_sub(x, 1, 7)
}

similarities2 <- similarities %>% 
        mutate(treaty_a = get_treaty(a),
        treaty_b = get_treaty(b)) %>% 
        count(treaty_a, treaty_b) %>% 
        arrange(desc(n)) %>% 
        filter(treaty_a != treaty_b) 
        

#Add years to similarities
parsed_treaties <- readRDS("parsed_treaties.rds")

parsed_treaties <- parsed_treaties %>% 
  mutate(document_id = basename(parsed_treaties$file) %>% str_replace("\\.htm", "")) %>%
  mutate(document_id_a = basename(parsed_treaties$file) %>% str_replace("\\.htm", "")) %>%
  mutate(document_id_b = basename(parsed_treaties$file) %>% str_replace("\\.htm", ""))

similarities2 <- similarities2 %>%
              mutate(document_id_a = treaty_a) %>%
              mutate(document_id_b = treaty_b) 
              
similarities2 <- left_join(parsed_treaties, similarities2, by = "document_id_a")

similarities2 <- subset(similarities2, select = -c(1, 2, 3, 4))

similarities2 <- similarities2 %>% 
                mutate(treaty_a_year = year)


similarities2 <- subset(similarities2, select = -c(1, 2, 3, 4))

similarities2 <- similarities2 %>%
                mutate(document_id_b = document_id_b.y)

similarities2 <- subset(similarities2, select = -c(4))

similarities2 <- left_join(parsed_treaties, similarities2, by = "document_id_b")

similarities2 <- similarities2 %>% 
                mutate(treaty_b_year = year)

similarities2 <- subset(similarities2, select = -c(1, 2, 3, 4, 5, 6, 7, 8))

similarities2 <- na.omit(similarities2)

similarities2 <- similarities2 %>%
                    mutate(borrow_span = (treaty_a_year - treaty_b_year))


```

```{r}
paragraph_network <- similarities %>% 
  mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
      filter(treaty_a != treaty_b)
  

fd_matches <- similarities2
```


```{#r}
#Old Code

matches %>% 
  mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
  count(treaty_a, treaty_b) %>% 
  arrange(desc(n)) %>% 
  filter(treaty_a != treaty_b) %>%
   View


fd_matches =  (matches %>% mutate(treaty_a = get_treaty(a),
         treaty_b = get_treaty(b)) %>% 
  count(treaty_a, treaty_b) %>% 
  arrange(desc(n)) %>% 
  filter(treaty_a != treaty_b)) 
```

##Networks

###Paragraph Level Borrowing
The following graph displays treaty borrowing at the paragraph level.
```{r}

sample_graph2 <- graph.data.frame(paragraph_network,directed = FALSE)

plot(sample_graph2, 
     layout = layout.auto,
    #vertex.label.cex = 0.7,
    vertex.label = NA,
    margin = -0.6,
    vertex.size = 1,
      main = "Network Graph of Paragraph Borrowing",
    edge.width = similarities$score)

```
###Decomposing the Paragraph Network

The following graph represents the largest cluster from above.
```{r}
components <-decompose(sample_graph2, mode = c("weak", "strong"), max.comps = NA,
  min.vertices = 3)

components_1_graph <- (components[[1]])

plot(components_1_graph,
     layout = layout.auto,
    #vertex.label.cex = 0.7,
    vertex.label = NA,
    margin = -0,
    vertex.size = 1,
    main = "Network Graph of Largest Paragraph Cluster",
    edge.width = similarities$score)
```

###Treaty Borrowing at the Document Level

The following are network graphs of the treaties with the edges representing the number of shared paragraphs. 
```{r}
parsed_treaties2 <- readRDS("parsed_treaties.rds")

parsed_treaties2 <- parsed_treaties2 %>%
      mutate(document_id = basename(parsed_treaties2$file) %>% str_replace("\\.htm", ""))

node_df <- subset(parsed_treaties2, select = -c(1, 2, 3, 4))
          
node_df <- node_df[, c(2,1)]

node_df <- node_df %>%
          mutate(treaty_lookup = document_id )

node_df <- node_df %>%
          mutate(decade = year %>% str_extract("\\d{3}"))

node_att_graph <- graph_from_data_frame(d = fd_matches, vertices = node_df, directed = FALSE)

sample_graph <- node_att_graph
  
  #Old way to create igraph = graph.data.frame(fd_matches,directed = FALSE)

plot(sample_graph, 
     layout = layout.auto,
    #vertex.label.cex = 0.7,
    vertex.label = NA,
    margin = -0,
     vertex.size = 3,
    main = "Network Graph of Treaty Borrowing",
    edge.width = fd_matches$n >2)
    
```


```{#r}

#Trial to recreate igraph with node attributes

parsed_treaties2 <- readRDS("parsed_treaties.rds")

parsed_treaties2 <- parsed_treaties2 %>%
      mutate(document_id = basename(parsed_treaties2$file) %>% str_replace("\\.htm", ""))

node_df <- subset(parsed_treaties2, select = -c(1, 2, 3, 4))
          
node_df <- node_df[, c(2,1)]


node_att_graph <- graph_from_data_frame(d = fd_matches, vertices = node_df, directed = FALSE)


plot(node_att_graph)

G <- node_att_graph

V(G)$color <- ifelse(V(G)$year =="1865", "lightblue", "orange")

plot(G, 
     layout = layout.auto, 
     vertex.size = 4, 
     vertex.label = NA, 
     edge.width = fd_matches$n >2)    

colrs <- c("red", "orange")
V(G)$color <- colrs[V(G)$treaty_a_year == "1865"]

#Attempt to seperate by decade
#seventeen_eighties <- filter(fd_matches, treaty_a_year == c(1780:1789))
                       
                       #| treaty_b_year == c(1780:1789))


```

```{r}
G <- node_att_graph

V(G)$color <- ifelse(V(G)$year > 1820 & V(G)$year< 1829, "lightblue", "orange") 

V(G)$color <- ifelse(V(G)$decade == "177", "blue", ifelse(V(G)$decade == "178","cyan", ifelse(V(G)$decade == "179","blueviolet", ifelse(V(G)$decade == "180","darkgreen", ifelse(V(G)$decade == "181","green", ifelse(V(G)$decade == "182","orange", ifelse(V(G)$decade == "183","gold", ifelse(V(G)$decade == "184","red", ifelse(V(G)$decade == "185","hotpink", ifelse(V(G)$decade == "186","yellow", ifelse(V(G)$decade == "187","black", ifelse(V(G)$decade == "188","tan", "white" ))))))))))))


plot(G, 
     layout = layout.auto,
     vertex.label.cex = 0.6,
     vertex.label.dist =0,
     vertex.label.degree = pi,
     vertex.size = 4, 
     margin = -0,
     #vertex.label = NA, 
     main = "Network Graph of Treaty Borrowing",
     edge.width = fd_matches$n >2)

legend("left", c("1770s","1780s", "1790s","1800s", "1810s", "1820s", "1830s", "1840s", "1850s", "1860s", "1870s", "1880s"),  pch=21,
       col=c("blue", "cyan", "blueviolet", "darkgreen", "green", "orange", "gold", "red", "hotpink","yellow", "black", "tan", "white")) 

t.bg= c("blue", "cyan", "blueviolet", "darkgreen", "green", "orange", "gold", "red", "hotpink","yellow", "black", "tan"),

legend(x=-1.5, y=-1.1, c("Newspaper","Television", "Online News"), pch=21,
       col="#777777", pt.bg=colrs, pt.cex=2, cex=.8, bty="n", ncol=1)
egend(2000,9.5, # places a legend at the appropriate place c(“Health”,”Defense”), # puts text in the legend

lty=c(1,1), # gives the legend appropriate symbols (lines)

lwd=c(2.5,2.5),col=c(“blue”,”red”)) # gives the legend lines the correct color and width

colors <- c("blue", "cyan", "blueviolet", "darkgreen", "green", "orange", "gold", "red", "hotpink","yellow", "black", "tan", "white")
```



```{r}
plot(sample_graph, 
     layout = layout.auto,
    #vertex.label.cex = 0.7,
    vertex.label = NA,
    margin = -0.1,
     vertex.size = 1,
    main = "Network Graph of Treaty Borrowing",
    edge.width = fd_matches$n >5)
```
###Decomposing the Document Network
```{r}
components_whole <-decompose(sample_graph, mode = c("weak", "strong"), max.comps = NA,
  min.vertices = 5)

plot(components_whole[[1]],
     layout = layout.auto,
    #vertex.label.cex = 0.6,
    vertex.label = NA,
    margin = -0,
     vertex.size = 1,
    main = "Title",
    edge.width = fd_matches$n >3)

```
The largest cluster:
```{r}
components_whole_1 <- (components_whole[[1]])

plot(components_whole_1, 
     layout = layout.auto,
    #vertex.label.cex = 0.6,
    vertex.label = NA,
    margin = -0.2,
     vertex.size = 1,
    main = "Network Graph of Largest Treaty Cluster",
    edge.width = fd_matches$n)



```
Attempt to split the graph apart futher by removing vertices and the decomposing.

```{r}
broken_graph <- sample_graph

removed_vertices <- c("cre0155", "com0600", "cre0214", "wya0145", "iow0208", "pot0168", "mia0531", "sau0207",  "qua0160")
#removed_edges <- c("osa0095|osa0167")

broken_graph <- delete_vertices(broken_graph, removed_vertices)                 #

#delete_edges(broken_graph, removed_edges) 
 
plot(broken_graph,
     layout = layout.auto,
    vertex.label.cex = 0.6,
    #vertex.label = NA,
    margin = -0.1,
    vertex.size = 1,
    main = "Network Graph of Largest Treaty Cluster",
    edge.width = fd_matches$n >3)

decomposed_broken_graph <-decompose(broken_graph, mode = c("weak", "strong"), max.comps = NA,
  min.vertices = 4)

plot(decomposed_broken_graph[[2]],
     layout = layout.auto,
    vertex.label.cex = 0.6,
    #vertex.label = NA,
    margin = -0.3,
     vertex.size = 1,
    main = "Title",
    edge.width = fd_matches$n >2)

G <- decomposed_broken_graph[[3]]

V(G)$color <- ifelse(V(G)$decade == "177", "blue", ifelse(V(G)$decade == "178","cyan", ifelse(V(G)$decade == "179","blueviolet", ifelse(V(G)$decade == "180","darkgreen", ifelse(V(G)$decade == "181","green", ifelse(V(G)$decade == "182","orange", ifelse(V(G)$decade == "183","gold", ifelse(V(G)$decade == "184","red", ifelse(V(G)$decade == "185","hotpink", ifelse(V(G)$decade == "186","yellow", ifelse(V(G)$decade == "187","black", ifelse(V(G)$decade == "188","tan", "white" ))))))))))))

plot(G, 
     layout = layout.auto,
     vertex.label.cex = 0.6,
     vertex.label.dist =0,
     vertex.label.degree = pi,
     vertex.size = 4, 
     margin = -0,
     #vertex.label = NA, 
     main = "Network Graph of Treaty Borrowing",
     edge.width = fd_matches$n >2)
```


Another decomposition with a higher number of minimum vertices.
```{r}
components_whole2 <-decompose(sample_graph, mode = c("weak", "strong"), max.comps = NA,
  min.vertices = 4)

plot(components_whole2[[8]],
     layout = layout.auto,
    vertex.label.cex = 0.6,
    #vertex.label = NA,
    margin = -0,
     vertex.size = 1,
    main = "Network Graph of Largest Treaty Cluster",
    edge.width = fd_matches$n >2)
```
The Sioux Cluster
```{r}
plot(components_whole2[[2]],
     layout = layout.auto,
    vertex.label.cex = 0.6,
    #vertex.label = NA,
    margin = -0,
     vertex.size = 1,
    main = "Sioux Bands Cluster, 1865",
    edge.width = fd_matches$n >3)
```


##PCA at the paragraph level. 
```{r}
#for paragraph level 
files <- list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-paragraphs",                    pattern = "*.txt",
                  full.names = TRUE)


reader <- function(f) {
  require(stringr)
  n <- parsed_treaties$file %>% str_replace("\\.txt", "")
  doc <- readr::read_file(f)
  names(doc) <- n
  doc
}

it_files <- ifiles(files, reader = reader)
it_tokens <- itoken(it_files,
                   tokenizer = tokenizers::tokenize_words)

vocab <- create_vocabulary(it_tokens)

pruned_vocab <- prune_vocabulary(vocab, term_count_min = 10,
term_count_max = 50000)
vectorizer <- vocab_vectorizer(pruned_vocab)

dtm <- create_dtm(it_tokens, vectorizer)
rownames(dtm) <- basename(files) 

dtmsimilarities <- wordVectors::cosineSimilarity(dtm[1:1000, , drop = FALSE], 
                                              dtm[1:1000, , drop = FALSE])
dtmsimilarities %>% View

dtm2 <- as.matrix(dtm)

pca <- prcomp(dtm2, scale. = FALSE)
plot(pca)
augment(pca) %>% select(1:6) %>% as_tibble() %>% View

augment(pca) %>%
ggplot(aes(.fittedPC1, .fittedPC2)) + 
geom_point() 

#(for labels) geom_text_repel(aes(label = .rownames))
#saveRDS(pca,"pca_indian_treaties_paragraph_level.rds")
```


##K-Means at the Document Level
 
```{r}

treatycorpus <- list.files("C:/Users/Joshua/Documents/rdata/indian_treaties/treaty-complete",                    pattern = "*.txt",
                   full.names = TRUE)
 
reader <- function(f) {
  require(stringr)
  n <- basename(f) %>% str_replace("\\.txt", "")
  doc <- readr::read_file(f)
  names(doc) <- n
  doc
}

it_files2 <- ifiles(treatycorpus, reader = reader)
it_tokens2 <- itoken(it_files2,
                   tokenizer = tokenizers::tokenize_words)

vocab2 <- create_vocabulary(it_tokens2)

pruned_vocab2 <- prune_vocabulary(vocab2, term_count_min = 10,
term_count_max = 50000)
vectorizer2 <- vocab_vectorizer(pruned_vocab2)

dtm2 <- create_dtm(it_tokens2, vectorizer2)
rownames(dtm2) <- basename(treatycorpus)

parsed_treaties <- readRDS("parsed_treaties.rds")
addyear <- basename(parsed_treaties$file) %>% str_replace("\\.htm", ".txt")


parsed_treaties <- parsed_treaties %>% 
  mutate(document_id = basename(parsed_treaties$file) %>% str_replace("\\.htm", ".txt"))

km <- kmeans(dtm2, centers = 10)

k_clusters <- tibble(document_id = rownames(dtm2),
                     cluster = km$cluster) %>% 
  left_join(parsed_treaties, by = "document_id")

k_clusters %>% arrange(cluster) %>% View

plot(km$cluster)

ggplot(k_clusters, aes(388, 388)) + geom_point()
```


Affinity Propogation Clustering
```{r}

scores_clustering <- similarities

section_names <- lsh_subset(scores_clustering)

lookup <- data_frame(section_names, index = 1:length(section_names))

lookup

scores_clustering <- scores_clustering %>% 
  left_join(lookup, by = c("a" = "section_names")) %>% 
  left_join(lookup, by = c("b" = "section_names")) 

scores_clustering

n <- length(section_names)
m <- sparseMatrix(i = scores_clustering$index.x,
                  j = scores_clustering$index.y,
                  x = scores_clustering$score,
                  dims = c(n, n), symmetric = TRUE)
colnames(m) <- section_names
rownames(m) <- section_names



cluster_cache <- "C:/Users/Joshua/Documents/rdata/indian_treaties/clusters.rds"
if (!file.exists(cluster_cache)) {
  timing <- system.time(
    clu <- apcluster(s = m,
                     maxits = 100e3, convits = 10e3,
                     q = 0,
                     lam = 0.975,
                     seed = 42325, 
                     includeSim = TRUE,
                     )
  )
  saveRDS(clu, cluster_cache)
 } else {
  clu <- readRDS(cluster_cache)
}

clusters <- clu@clusters 
names(clusters) <- names(clu@exemplars)
clusters <- lapply(clusters, names)


exemplars_corpus <- corpus2[names(clusters)]
exemplars_scores <- exemplars_corpus %>% 
  lsh(bands = 40) %>% 
  lsh_candidates() %>% 
  lsh_compare(exemplars_corpus, jaccard_similarity) %>% 
  arrange(desc(score))

boxplot(exemplars_scores$score)
hist(exemplars_scores$score)

join_threshold <- 0.15
exemplars_scores <- exemplars_scores %>% 
  filter(score >= 0.19)

hist(exemplars_scores$score)
```

Creating a Data Frame
```{r}
clusters_df <- clusters %>% 
  seq_along() %>% 
  lapply(function(i) {
    exemplar <- names(clusters)[i]
    doc <- clusters[[i]]
    data_frame(exemplar, doc, cluster_id = i)
  }) %>% 
  bind_rows() %>% 
  group_by(cluster_id) %>% 
  mutate(n = n()) %>% 
  ungroup() %>% 
  arrange(desc(n))

clusters_df

dir.create("C:/Users/Joshua/Documents/rdata/indian_treaties/clusters")

write_csv(clusters_df, "C:/Users/Joshua/Documents/rdata/indian_treaties/clusters/clusters.csv")

extract_code_names <- function(section_names) {
  splits <- str_split(section_names, "-")
  vapply(splits, `[`, character(1), 1)
}

exemplars_summary <- clusters_df$exemplar %>% 
  extract_code_names() %>% 
  table() %>% 
  as.data.frame() %>% as_data_frame() %>% 
  rename(., code = `.`) %>% 
  arrange(desc(Freq))
```




```{r}

#Check if Needed
join_threshold <- 0.15
exemplars_scores <- exemplars_scores %>% 
  filter(score >= 0.15)

join_clusters <- function(row) {
  exs <- c(row$a, row$b)
  minval <- which.min(extract_date(exs))
  exemplar <- exs[minval]
  duplicate <- exs[ifelse(minval == 1, 2, 1)]
  clusters[[exemplar]] <<- c(clusters[[exemplar]], clusters[[duplicate]])
  clusters[[duplicate]] <<- NULL
  dplyr::as_data_frame(row)
}

exemplars_scores %>% 
  rowwise() %>% 
  do(join_clusters(.))

hist(exemplars_scores$score)


```


```{r}

cluster181 <- c("ari0237-00012", "bel0239-00011", "che0232-00012","cro0244-00010","hun0235-00010", "mak0260-00010", "man0242-00012","ogl0230-00011", "oto0256-00010", "paw0258-00011", "pon0225-00010", "rog0603-00012", "sio0227-00014", "uta0856-00011")


cluster181 <- get_treaty(cluster181)


cluster_df_years <- clusters_df %>%
              mutate(document_id_a = get_treaty(exemplar)) %>%
              mutate(document_id_b = get_treaty(doc)) 
              
cluster_df_years <- left_join(parsed_treaties, cluster_df_years, by = "document_id_a")

cluster_df_years <- subset(cluster_df_years, select = -c(1, 2, 3, 4))

cluster_df_years <- cluster_df_years %>% 
                mutate(exemplar_year = year)


cluster_df_years <- subset(cluster_df_years, select = -c(1, 2, 3, 4))

cluster_df_years <- cluster_df_years %>%
                mutate(document_id_b = document_id_b.y)

cluster_df_years <- subset(cluster_df_years, select = -c(5))

cluster_df_years <- left_join(parsed_treaties, cluster_df_years, by = "document_id_b")

cluster_df_years <- cluster_df_years %>% 
                mutate(doc_year = year)

cluster_df_years <- subset(cluster_df_years, select = -c(1, 2, 3, 4, 5, 6, 7, 8))

cluster_df_years <- na.omit(cluster_df_years)

cluster_df_years <- cluster_df_years %>%
                    mutate(borrow_span = (doc_year - exemplar_year))

hist(abs(cluster_df_years$borrow_span),
main="Histogram of Borrowing Across Time", 
     xlab="Difference in time between exemplar and borrower", 
     border="blue", 
     col="green",
     xlim=c(0,60),
     las=1, 
     breaks=50)


```

```{r}
g <- make_ring(10) %>%
  delete_edges(seq(1, 9, by = 2))
g

plot(g)
g <- make_ring(10) %>%
  delete_edges("8|9")
plot(g)
```


